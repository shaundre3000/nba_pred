{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from glob import glob\n",
    "import numpy as np\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import cross_val_predict\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.kernel_ridge import KernelRidge\n",
    "import warnings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def parse_conference_rank(row):\n",
    "    \"\"\"\n",
    "    :return: Parse out conference rank and Team from standings on basketball reference.\n",
    "    \"\"\"\n",
    "    team_split = row['Team'].split('(')\n",
    "    row['conference_rank'] = int(team_split[1][0])\n",
    "    if '*' in team_split[0]:\n",
    "        row['Team'] = team_split[0][:-1]\n",
    "    else:\n",
    "        row['Team'] = team_split[0]\n",
    "\n",
    "    return row"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_standings(standings_df, year, i):\n",
    "    \"\"\"\n",
    "    :param standings_df: Dataframe result from read_html of basketball reference\n",
    "    :param year: between 2005 - 2016\n",
    "    :param i: 1st df for each year is eastern conference, 2nd is western conference\n",
    "    :return: Clean up data and add columns for conference, year, team and rank.\n",
    "    \"\"\"\n",
    "    if i == 0:\n",
    "        conf = 'Eastern'\n",
    "        val = 1\n",
    "    else:\n",
    "        conf = 'Western'\n",
    "        val = 0\n",
    "\n",
    "    standings_df['eastern_conference'] = val\n",
    "    standings_df['year'] = year\n",
    "    standings_df.dropna(inplace=True)\n",
    "    standings_df.rename(columns={'{} Conference'.format(conf): 'Team'}, inplace=True)\n",
    "    standings_df['Team'] = standings_df['Team'].str.replace(u'\\xa0', u'')\n",
    "    standings_df.drop('PS/G', axis=1, inplace=True)\n",
    "\n",
    "    return standings_df.apply(parse_conference_rank, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_all_standings():\n",
    "    \"\"\"\n",
    "    :return: Pull yearly standings data from basketball reference and return one\n",
    "    concatenated DataFrame.\n",
    "    \"\"\"\n",
    "    standing_dfs = []\n",
    "    for year in range(2005, 2017):\n",
    "        url = 'http://www.basketball-reference.com/leagues/NBA_{}.html'.format(year)\n",
    "        eastern_western_standings = pd.read_html(url)\n",
    "        for i, standings_df in enumerate(eastern_western_standings[:2]):\n",
    "            standings_df = get_standings(standings_df, year, i)\n",
    "            standing_dfs.append(standings_df)\n",
    "\n",
    "    return pd.concat(standing_dfs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def clean_up_team_df(folder):\n",
    "    \"\"\"\n",
    "    :param folder: Data is manually downloaded from basketball reference because the web-scraping\n",
    "     is too tedious.\n",
    "    :return: Grab offensive and defensive stats for each team for each year and clean up the data\n",
    "     and apply correct data types.\n",
    "    \"\"\"\n",
    "    team_dfs = []\n",
    "    files = glob(folder + '/*.csv')\n",
    "    for file in files:\n",
    "        team_df = pd.read_csv(file)\n",
    "        off_def = file.split('season')\n",
    "        team_df.dropna(inplace=True)\n",
    "        team_df = team_df.convert_objects(convert_numeric=True)\n",
    "\n",
    "        if 'opp' in off_def[1]:\n",
    "            team_df.drop(['G', 'MP'], axis=1, inplace=True)\n",
    "            team_df.rename(columns={'PA/G': 'PA_G'})\n",
    "            team_df.columns = ['Def_Rank', 'Team'] + ['{}_opp'.format(col) for col in team_df.columns[2:]]\n",
    "\n",
    "        else:\n",
    "            team_df.rename(columns={'Rank': 'Off_Rank'})\n",
    "            try:\n",
    "                team_df['PS_G'] = team_df['PS_G'].str.replace(\"\\\\\", '')\n",
    "            except AttributeError:\n",
    "                pass\n",
    "            team_df['playoff_appearance'] = team_df.apply(lambda row: 1 if '*' in row['Team'] else 0, axis=1)\n",
    "\n",
    "        team_df['year'] = int(file.split('yearly_data/')[-1][:4])\n",
    "        # use better method than convert_objects\n",
    "        team_df['Team'] = team_df['Team'].str.replace('*', '')\n",
    "        team_df.columns = team_df.columns.str.replace('%', '_Perc')\n",
    "\n",
    "        team_dfs.append(team_df)\n",
    "\n",
    "    return pd.merge(team_dfs[0], team_dfs[1], how='left', on=['Team', 'year'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_team_detailed_stats():\n",
    "    \"\"\"\n",
    "    :return: Root folder of where all detailed stats live in hard drive. Concatenate\n",
    "     each year of data into one single DataFrame.\n",
    "    \"\"\"\n",
    "    root_folder = 'yearly_data/*'\n",
    "    year_folders = glob(root_folder)\n",
    "\n",
    "    return pd.concat([clean_up_team_df(folder) for folder in year_folders])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_all_stars():\n",
    "    \"\"\"\n",
    "    :return: Additional data about all stars each year available on basketball reference.\n",
    "    Loop through and pull that data.\n",
    "    \"\"\"\n",
    "    all_star_dfs = []\n",
    "    for year in range(2005, 2017):\n",
    "        all_star_url = 'http://www.basketball-reference.com/allstar/NBA_{}.html'.format(year)\n",
    "        west_east = pd.concat([df[['Unnamed: 0', 'Totals']] for df in pd.read_html(all_star_url)[1:]])\n",
    "        west_east = west_east[west_east['Unnamed: 0'] != 'Reserves'].dropna()\n",
    "        west_east['all_star_count'] = west_east.groupby('Totals')['Totals'].transform('count')\n",
    "        west_east = west_east[['Totals', 'all_star_count']].drop_duplicates()\n",
    "        west_east['year'] = year\n",
    "        all_star_dfs.append(west_east)\n",
    "\n",
    "    all_star_df = pd.concat(all_star_dfs)\n",
    "    all_star_df.rename(columns={'Totals': 'Team Abbrev'}, inplace=True)\n",
    "    team_mapping = pd.read_csv('team_mapping.csv')\n",
    "    all_star_df = pd.merge(all_star_df, team_mapping, how='left', on='Team Abbrev')\n",
    "\n",
    "    return all_star_df.drop('Team Abbrev', axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_all_nba():\n",
    "    \"\"\"\n",
    "    :return: Manually downloaded data for each year's first all nba team to add to features.\n",
    "    \"\"\"\n",
    "    first_all_nba = pd.read_csv('all_nba.csv')\n",
    "    first_all_nba['all_nba_count'] = first_all_nba.groupby(['year', 'Team'])['Team'].transform('count')\n",
    "\n",
    "    return first_all_nba.drop('player', axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def combine_standings_metrics(total_standings_df, team_detailed_df, all_star_df, first_all_nba):\n",
    "    \"\"\"\n",
    "    :param total_standings_df:\n",
    "    :param team_detailed_df:\n",
    "    :param all_star_df:\n",
    "    :param first_all_nba:\n",
    "    :return: Combine standings, offensive + defense statistics, all star, and first team all nba\n",
    "    data into a single DataFrame. Drop any columns that are highly correlated or not useful in the model.\n",
    "    Normalize some statistics to be at a per game basis.\n",
    "    \"\"\"\n",
    "    combined_df = pd.merge(total_standings_df, team_detailed_df, how='left', on=['Team', 'year'])\n",
    "    combined_df = pd.merge(combined_df, all_star_df, how='left', on=['Team', 'year'])\n",
    "    combined_df = pd.merge(combined_df, first_all_nba, how='left', on=['Team', 'year'])\n",
    "\n",
    "    combined_df['GB'] = combined_df['GB'].str.replace('â€”', '0')\n",
    "    for col in ['GB', 'PS_G']:\n",
    "        combined_df[col] = combined_df[col].astype(float)\n",
    "\n",
    "    for orig_val, new_val in [['%', '_Perc'], ['/', '_'], ['3', 'three'], ['2', 'two']]:\n",
    "        combined_df.columns = combined_df.columns.str.replace(orig_val, new_val)\n",
    "    corr_cols = ['Rk', 'SRS', 'W', 'L', 'GB', 'PA_G', 'conference_rank', 'Rank', 'MP', 'FG', 'FGA', 'FG_Perc',\n",
    "                 'FG_Perc_opp', 'threeP', 'threePA', 'twoP', 'twoPA', 'FT', 'FTA', 'TRB', 'PTS', 'Def_Rank',\n",
    "                 'FG_opp', 'FGA_opp', 'threePA_opp', 'threeP_opp', 'twoP_opp', 'twoPA_opp', 'FT_opp', 'FTA_opp',\n",
    "                 'TRB_opp', 'PTS_opp', 'PS_G', 'PA_G_opp', 'STL_opp', 'TOV_opp', 'eastern_conference',\n",
    "                 'FT_Perc_opp', 'BLK_opp', 'AST', 'BLK', 'DRB', 'DRB_opp', 'AST_opp']\n",
    "    combined_df.drop(corr_cols, axis=1, inplace=True)\n",
    "\n",
    "    normalize_cols = ['ORB', 'STL', 'TOV', 'PF', 'ORB_opp', 'PF_opp']\n",
    "    for col in normalize_cols:\n",
    "        combined_df['{}_G'.format(col)] = combined_df[col] / combined_df['G']\n",
    "\n",
    "    combined_df.drop(normalize_cols + ['G'], axis=1, inplace=True)\n",
    "    combined_df['next_year_wl_perc'] = combined_df.groupby(['Team'])['W_L_Perc'].shift(-1)\n",
    "    \n",
    "    for col in ['all_star_count', 'all_nba_count']:\n",
    "        combined_df[col] = combined_df[col].fillna(0)\n",
    "\n",
    "    return combined_df.drop(['Team', 'W_L_Perc'], axis=1).dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def random_forest(combined_df):\n",
    "    \"\"\"\n",
    "    :return: Attempt random forest regression as quick model.\n",
    "    \"\"\"\n",
    "    model = RandomForestRegressor(random_state=0, n_estimators=50)\n",
    "    model_data = combined_df.drop(['next_year_wl_perc', 'year'], axis=1)\n",
    "    y = combined_df.next_year_wl_perc\n",
    "\n",
    "    model.fit(model_data, y)\n",
    "    scores = cross_val_score(model, model_data, y)\n",
    "    print('Random Forest Results:')\n",
    "    print('CV AUC {}, Average AUC {}'.format(scores, scores.mean()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def polynomial_reg(combined_df):\n",
    "    \"\"\"\n",
    "    :return: Build pipeline that will create polynomial regression observations (degree 2)\n",
    "    and use a Kernel Ridge regression to create a predictive model.  Test the data using\n",
    "    each year as an test to evaluate mean squared error.\n",
    "    \"\"\"\n",
    "    train_y = combined_df['next_year_wl_perc']\n",
    "    train_X = combined_df.drop(['next_year_wl_perc', 'year'], axis=1)\n",
    "    log_cols = train_X.columns.tolist()\n",
    "    for i in [5, 5, 5]:\n",
    "        log_cols.pop(i)\n",
    "#     train_X[log_cols] = train_X[log_cols].apply(np.log10)\n",
    "\n",
    "    polynomial_features = PolynomialFeatures(degree=2, include_bias=False)\n",
    "    linear_regression = KernelRidge(alpha=1)\n",
    "\n",
    "    pipeline = Pipeline([(\"polynomial_features\", polynomial_features), (\"clf\", linear_regression)])\n",
    "    pipeline.fit(train_X, train_y)\n",
    "\n",
    "    # Evaluate the models using cross validation\n",
    "    scores = cross_val_score(pipeline, train_X, train_y, scoring=\"neg_mean_squared_error\", cv=10)\n",
    "    print('\\n')\n",
    "    print('Polynomial Regression Results:')\n",
    "    print(\"Train MSE = {:.2e}(+/- {:.2e})\".format(-scores.mean(), scores.std()))\n",
    "    full_preds = []\n",
    "    print('\\n')\n",
    "    for year in range(2005, 2016):\n",
    "        test_X = combined_df[combined_df['year'] == year]\n",
    "        test_y = test_X['next_year_wl_perc']\n",
    "        test_X.drop(['next_year_wl_perc', 'year'], axis=1, inplace=True)\n",
    "        predicted = cross_val_predict(pipeline, test_X, test_y)\n",
    "        predicted_scores = cross_val_score(pipeline, test_X, test_X, scoring=\"neg_mean_squared_error\")\n",
    "\n",
    "        last_season_wl = pd.DataFrame(predicted, columns=['Predict'.format(year + 1)])\n",
    "        last_season_wl = pd.DataFrame(test_y).reset_index(drop=True).join(last_season_wl)\n",
    "        last_season_wl['year'] = year\n",
    "\n",
    "        for exist_col, new_col in zip(last_season_wl.columns, ['actual_games_won', 'predicted_games_won']):\n",
    "            last_season_wl[new_col] = last_season_wl[exist_col] * 82\n",
    "        full_preds.append(last_season_wl)\n",
    "\n",
    "        print(\"{}: Test MSE = {:.2e}(+/- {:.2e})\".format(year, -predicted_scores.mean(), predicted_scores.std()))\n",
    "\n",
    "    preds_df = pd.concat(full_preds)\n",
    "    preds_df['delta'] = abs(preds_df['actual_games_won'] - preds_df['predicted_games_won'])\n",
    "    \n",
    "    print('\\n')\n",
    "    print('2016 average prediction delta by games is {0:.2f}'.format(preds_df['delta'].mean()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def main():\n",
    "\n",
    "    warnings.filterwarnings('ignore')\n",
    "    team_detailed_df = get_team_detailed_stats()\n",
    "    total_standings_df = get_all_standings()\n",
    "    all_star_df = get_all_stars()\n",
    "    first_all_nba = get_all_nba()\n",
    "    combined_df = combine_standings_metrics(total_standings_df, team_detailed_df, all_star_df, first_all_nba)\n",
    "\n",
    "    # models\n",
    "    random_forest(combined_df)\n",
    "    polynomial_reg(combined_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest Results:\n",
      "CV AUC [ 0.69536482  0.74823411  0.30539638], Average AUC 0.582998436645731\n",
      "\n",
      "\n",
      "Polynomial Regression Results:\n",
      "Train MSE = 8.67e-03(+/- 6.37e-03)\n",
      "\n",
      "\n",
      "2005: Test MSE = 1.82e-01(+/- 1.04e-01)\n",
      "2006: Test MSE = 2.71e-02(+/- 7.32e-03)\n",
      "2007: Test MSE = 7.06e-02(+/- 2.84e-02)\n",
      "2008: Test MSE = 2.66e-02(+/- 1.35e-02)\n",
      "2009: Test MSE = 4.67e-02(+/- 2.75e-02)\n",
      "2010: Test MSE = 4.22e-02(+/- 3.83e-02)\n",
      "2011: Test MSE = 3.47e-02(+/- 7.66e-03)\n",
      "2012: Test MSE = 4.22e-02(+/- 5.62e-03)\n",
      "2013: Test MSE = 3.46e-02(+/- 8.32e-03)\n",
      "2014: Test MSE = 2.49e-02(+/- 9.39e-03)\n",
      "2015: Test MSE = 5.02e-02(+/- 3.86e-02)\n",
      "\n",
      "\n",
      "2016 average prediction delta by games is 10.06\n"
     ]
    }
   ],
   "source": [
    "if __name__ == '__main__':\n",
    "    main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
